# MLflow End-to-End Pipeline with Best Practices

## ğŸ“Œ Project Overview
This project demonstrates a **Machine Learning pipeline** with **MLflow** for tracking experiments and model training. It follows industry best practices and includes:

- **Data Loading**: Using `sklearn.datasets`
- **Data Preprocessing**: Feature selection and splitting
- **Model Training**: Random Forest with hyperparameters
- **Model Evaluation**: Performance metrics logged to MLflow
- **MLflow Integration**: Tracking and visualizing experiments

---

## ğŸš€ Getting Started
### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/yourusername/mlflow-pipeline.git
cd mlflow-pipeline
```

### **2ï¸âƒ£ Set Up the Conda Environment**
Ensure you have **Miniconda** or **Anaconda** installed. Then run:
```bash
conda env create -f environment.yml
conda activate mlflow-pipeline
```

### **3ï¸âƒ£ Run the Pipeline**
```bash
python src/run_pipeline.py --n_estimators 150 --max_depth 5 --test_size 0.2
```

### **4ï¸âƒ£ Start MLflow UI** *(Optional but Recommended)*
```bash
mlflow ui
```
Then open **http://localhost:5000** to view experiment logs.

---

## ğŸ“‚ Project Structure
```
mlflow_pipeline/
â”‚â”€â”€ data/               # Dataset (if applicable)
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py  # Load dataset from sklearn
â”‚   â”œâ”€â”€ preprocessing.py # Data processing & splitting
â”‚   â”œâ”€â”€ train.py        # Model training script
â”‚   â”œâ”€â”€ evaluate.py     # Model evaluation metrics
â”‚   â”œâ”€â”€ run_pipeline.py # Main pipeline script
â”‚â”€â”€ tests/              # Unit tests
â”‚â”€â”€ environment.yml     # Conda dependencies
â”‚â”€â”€ README.md           # Project documentation
```

---

## ğŸ” Example Output
```
Model logged with accuracy: 0.95
Run `mlflow ui` to view experiment logs.
```

---

## ğŸ“¢ Contributing
Feel free to **fork** this repository, submit **issues**, or create **pull requests**.

---

## ğŸ“ License
This project is open-source and available under the **MIT License**.

---

ğŸ’¡ **Showcase this to your interviewer by explaining:**
- How MLflow tracks experiments
- Why modularized code improves maintainability
- How hyperparameter tuning improves model performance

ğŸš€ **Good luck with your interview!**

